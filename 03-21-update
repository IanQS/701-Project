Current situation:

Document level analysis appears to be a more solved problem than anticipated. In particular, on the document level there is sufficient bias towards one party that small and confusing phrases no longer matter. For us, this may be particularly exaggerated by the small size of the political speech corpus (just several hunderd speeches). In any case, using vectors generated by doc2vec, a simple logistic regression gets about 85% accuracy which would be hard to iterate on.

How do2vec baseline was generated: https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis#disqus_thread ("Using Doc2Vec to Analyze Movie Reviews" section adapted for speeches instead of reviews).

Despite this, sentence-level categorization remains an open-ended problem. Even our inspiration paper gets only 70% accuracy - giving us plenty of room to improve (http://www.aclweb.org/anthology/P/P14/P14-1105.pdf). Furthermore, it be cool to test their method on the political speeches.

Where to go to on the sentence level:
Easy:
- Recreate 4.2 results on IBC corpus (once we get access to it)
- Recreate RNN-1 and RNN-1(w2v) models of political speeches corpus (section 4.1 here may have other critical details http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)

Hard:
- Recreate RNN-2 model with political speech corpus. This is difficult because we do not have phrase level annotations of the speeches, in particular the previous paper achieved these sub-tree labels using crowd-sourcing which we can not extend to our corpus in the span of this project :( 
- Try more complicated techniques for RNNs. In particular, this paper only implements basic RNNs where each node combines "word vectors" from children into a new "phrase vector". The sentiment-analysis work in this area has built more interesting models. http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf (instead of implementing 4.1 here, implement 4.2 or 4.3) We could even try other approaches such as LSTMs. BUT....Possible complication: In particular, the original paper tried to implement "syntactically-united" RNNs but found that they did not have enough data to tune the model sufficiently.
- Since we don't have inner node labels, we can explore techniques where these inner labels would be hidden anyway - def a lot of experimentation to do here.
- Bootstrap phrase annotations for political speech corpus, instead of crowd sourcing. Perhaps existing algorithms are good enough to help us to here.
